{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Structures for Data Science (Python) — Jupyter Notebook\n",
        "\n",
        "**Last updated:** 2026-02-07\n",
        "\n",
        "This notebook is a hands-on lab that teaches the most useful data structures for data science work in Python.\n",
        "\n",
        "**How to use this notebook**\n",
        "- Read the concept cells, then run the code cells.\n",
        "- After each section, try the short exercises.\n",
        "- This notebook assumes basic Python (variables, functions, loops).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learning goals\n",
        "By the end, you will be able to:\n",
        "- Choose the right structure for a task (list vs dict vs set vs array)\n",
        "- Explain time/space tradeoffs using Big-O intuition\n",
        "- Use stacks, queues, heaps, and deques for common DS workflows\n",
        "- Work confidently with NumPy arrays and pandas Series/DataFrames\n",
        "- Recognize when graphs/trees are the right mental model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Setup\n",
        "We’ll import a few standard libraries used throughout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import time\n",
        "from collections import Counter, defaultdict, deque\n",
        "import heapq\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Big-O intuition (for data science)\n",
        "In DS work, performance issues often show up when:\n",
        "- A loop grows with data size (N)\n",
        "- Nested loops (N²) appear unintentionally\n",
        "- We repeatedly search a list instead of using a hash-based structure (dict/set)\n",
        "\n",
        "### Common operations (rule-of-thumb)\n",
        "- **List**: append O(1) amortized, search (`x in list`) O(N)\n",
        "- **Dict/Set**: insert/lookup O(1) average\n",
        "- **Sorting**: O(N log N)\n",
        "\n",
        "We’ll do a quick timing comparison: list membership vs set membership.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hits_list: 50000 time: 48.7773 sec\n",
            "hits_set : 50000 time: 0.0075 sec\n"
          ]
        }
      ],
      "source": [
        "# Timing: list membership vs set membership\n",
        "N = 200_000\n",
        "items = list(range(N))\n",
        "items_set = set(items)\n",
        "\n",
        "targets = [random.randrange(N) for _ in range(50_000)]\n",
        "\n",
        "t0 = time.time()\n",
        "hits_list = sum(1 for x in targets if x in items)   # O(N) membership each time\n",
        "t1 = time.time()\n",
        "\n",
        "t2 = time.time()\n",
        "hits_set = sum(1 for x in targets if x in items_set)  # O(1) average membership\n",
        "t3 = time.time()\n",
        "\n",
        "print(\"hits_list:\", hits_list, \"time:\", round(t1-t0, 4), \"sec\")\n",
        "print(\"hits_set :\", hits_set,  \"time:\", round(t3-t2, 4), \"sec\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 1\n",
        "1. Increase `N` to 1,000,000 and rerun.\n",
        "2. What happens to the timing gap? Why?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Python lists: flexible sequences\n",
        "Lists are great for:\n",
        "- Collecting records\n",
        "- Maintaining order\n",
        "- Iterating\n",
        "\n",
        "Less great for:\n",
        "- Frequent membership checks\n",
        "- Deleting from the middle repeatedly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3, 1, 4, 1, 5, 9, 2, 6]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[9, 1, 1, 25, 81]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Basic list patterns\n",
        "values = [3, 1, 4, 1, 5]\n",
        "values.append(9)\n",
        "values.extend([2, 6])\n",
        "print(values)\n",
        "\n",
        "# Common DS pattern: build and transform\n",
        "squared = [x*x for x in values if x % 2 == 1]\n",
        "squared\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Slicing and copying\n",
        "Be careful: `a = b` does not copy a list; it references the same object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a: [1, 2, 3, 4]\n",
            "b: [1, 2, 3, 4] (same as a)\n",
            "c: [1, 2, 3] (copy)\n"
          ]
        }
      ],
      "source": [
        "a = [1, 2, 3]\n",
        "b = a          # same object\n",
        "c = a[:]       # shallow copy\n",
        "a.append(4)\n",
        "\n",
        "print(\"a:\", a)\n",
        "print(\"b:\", b, \"(same as a)\")\n",
        "print(\"c:\", c, \"(copy)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 2\n",
        "Given a list of numbers, create a new list that contains only values above the mean.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(57.36666666666667,\n",
              " [63,\n",
              "  65,\n",
              "  36,\n",
              "  61,\n",
              "  66,\n",
              "  13,\n",
              "  2,\n",
              "  80,\n",
              "  78,\n",
              "  98,\n",
              "  32,\n",
              "  22,\n",
              "  100,\n",
              "  98,\n",
              "  90,\n",
              "  14,\n",
              "  4,\n",
              "  26,\n",
              "  48,\n",
              "  79,\n",
              "  51,\n",
              "  31,\n",
              "  69,\n",
              "  22,\n",
              "  89,\n",
              "  42,\n",
              "  80,\n",
              "  73,\n",
              "  94,\n",
              "  95],\n",
              " [63, 65, 61, 66, 80, 78, 98, 100, 98, 90, 79, 69, 89, 80, 73, 94, 95])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nums = [random.randint(0, 100) for _ in range(30)]\n",
        "mean_val = sum(nums) / len(nums)\n",
        "above_mean = [x for x in nums if x > mean_val]\n",
        "mean_val, nums, above_mean\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Tuples: lightweight, immutable records\n",
        "Tuples are good for:\n",
        "- Fixed-size records (like a row)\n",
        "- Dictionary keys (when you need a composite key)\n",
        "- Safer data that shouldn’t change\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "row = (\"TX\", \"Dallas\", 1300000)\n",
        "state, city, population = row\n",
        "state, city, population\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Dictionaries: fast lookup (hash tables)\n",
        "Dictionaries are the workhorse for:\n",
        "- Mapping IDs → records\n",
        "- Counting categories\n",
        "- Caching intermediate results\n",
        "\n",
        "### Pattern: counting with dict / Counter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = \"data science is science about data\"\n",
        "counts = Counter(text.split())\n",
        "counts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Defaultdict for grouping\n",
        "records = [\n",
        "    {\"dept\": \"Cardiology\", \"cost\": 1200},\n",
        "    {\"dept\": \"Cardiology\", \"cost\": 900},\n",
        "    {\"dept\": \"Oncology\", \"cost\": 3000},\n",
        "    {\"dept\": \"Oncology\", \"cost\": 2800},\n",
        "    {\"dept\": \"ER\", \"cost\": 600},\n",
        "]\n",
        "\n",
        "by_dept = defaultdict(list)\n",
        "for r in records:\n",
        "    by_dept[r[\"dept\"]].append(r[\"cost\"])\n",
        "\n",
        "by_dept, {k: sum(v)/len(v) for k,v in by_dept.items()}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 3\n",
        "Group patients by risk quadrant.\n",
        "- Input: list of dicts with keys `patient_id` and `risk_quadrant`\n",
        "- Output: dict mapping quadrant → list of patient_ids\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "patients = [\n",
        "    {\"patient_id\": \"P001\", \"risk_quadrant\": \"High\"},\n",
        "    {\"patient_id\": \"P002\", \"risk_quadrant\": \"Rising\"},\n",
        "    {\"patient_id\": \"P003\", \"risk_quadrant\": \"High\"},\n",
        "    {\"patient_id\": \"P004\", \"risk_quadrant\": \"Low\"},\n",
        "    {\"patient_id\": \"P005\", \"risk_quadrant\": \"Rising\"},\n",
        "]\n",
        "\n",
        "grouped = defaultdict(list)\n",
        "for p in patients:\n",
        "    grouped[p[\"risk_quadrant\"]].append(p[\"patient_id\"])\n",
        "\n",
        "dict(grouped)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Sets: uniqueness + fast membership\n",
        "Sets are ideal for:\n",
        "- Deduplicating\n",
        "- Fast membership checks\n",
        "- Set operations: union, intersection, difference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = {\"hypertension\", \"diabetes\", \"asthma\"}\n",
        "b = {\"diabetes\", \"cad\"}\n",
        "\n",
        "print(\"union:\", a | b)\n",
        "print(\"intersection:\", a & b)\n",
        "print(\"difference:\", a - b)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 4\n",
        "Given two lists of patient IDs (screened vs enrolled), compute:\n",
        "- IDs screened but not enrolled\n",
        "- IDs enrolled but not screened\n",
        "- IDs in both\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "screened = [\"P001\", \"P002\", \"P003\", \"P010\"]\n",
        "enrolled  = [\"P002\", \"P003\", \"P004\"]\n",
        "\n",
        "S = set(screened)\n",
        "E = set(enrolled)\n",
        "\n",
        "screened_not_enrolled = S - E\n",
        "enrolled_not_screened = E - S\n",
        "both = S & E\n",
        "\n",
        "screened_not_enrolled, enrolled_not_screened, both\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Deques: queues and sliding windows\n",
        "`collections.deque` supports O(1) append/pop from both ends.\n",
        "Common DS use cases:\n",
        "- FIFO queue\n",
        "- Moving/sliding windows\n",
        "- Breadth-first search (BFS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q = deque()\n",
        "q.append(\"A\")\n",
        "q.append(\"B\")\n",
        "q.append(\"C\")\n",
        "\n",
        "first = q.popleft()  # FIFO\n",
        "print(\"popped:\", first)\n",
        "print(\"queue:\", list(q))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sliding window example: moving average\n",
        "x = [random.randint(0, 10) for _ in range(20)]\n",
        "k = 5\n",
        "\n",
        "window = deque(maxlen=k)\n",
        "avgs = []\n",
        "for val in x:\n",
        "    window.append(val)\n",
        "    if len(window) == k:\n",
        "        avgs.append(sum(window)/k)\n",
        "\n",
        "x, avgs[:5], len(avgs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Stacks: LIFO workflows\n",
        "Python lists can act as stacks using `.append()` and `.pop()`.\n",
        "Stacks appear in:\n",
        "- Undo features\n",
        "- Depth-first search (DFS)\n",
        "- Parsing / parentheses matching\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stack = []\n",
        "for ch in \"ABCDE\":\n",
        "    stack.append(ch)\n",
        "\n",
        "while stack:\n",
        "    print(stack.pop(), end=\" \")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 5: Parentheses matching\n",
        "Write a function `is_balanced(s)` that returns True if parentheses are balanced.\n",
        "Test on: `\"(a+b) * (c+d)\"`, `\"(a+b))\"`, `\"((a+b)\"`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def is_balanced(s: str) -> bool:\n",
        "    stack = []\n",
        "    for ch in s:\n",
        "        if ch == \"(\":\n",
        "            stack.append(ch)\n",
        "        elif ch == \")\":\n",
        "            if not stack:\n",
        "                return False\n",
        "            stack.pop()\n",
        "    return len(stack) == 0\n",
        "\n",
        "tests = [\"(a+b) * (c+d)\", \"(a+b))\", \"((a+b)\"]\n",
        "[(t, is_balanced(t)) for t in tests]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Heaps (priority queues)\n",
        "Heaps support fast access to the smallest element.\n",
        "Use cases:\n",
        "- Top-K problems (most common in DS)\n",
        "- Scheduling\n",
        "- Streaming analytics\n",
        "\n",
        "Python provides `heapq` (a min-heap).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = [random.randint(0, 1000) for _ in range(20)]\n",
        "k = 5\n",
        "\n",
        "top_k = heapq.nlargest(k, data)\n",
        "bottom_k = heapq.nsmallest(k, data)\n",
        "\n",
        "data, top_k, bottom_k\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 6: Top-K frequent items\n",
        "Given a list of diagnosis codes, find the 3 most common.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dx = [\"I10\", \"E11.9\", \"I10\", \"I25.10\", \"E11.9\", \"I10\", \"E78.5\", \"E78.5\", \"E78.5\", \"I25.10\"]\n",
        "freq = Counter(dx)\n",
        "top3 = freq.most_common(3)\n",
        "freq, top3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) NumPy arrays: fast numeric structure\n",
        "NumPy arrays are:\n",
        "- Homogeneous (single dtype)\n",
        "- Vectorized (fast operations)\n",
        "- Memory-efficient\n",
        "\n",
        "Use arrays for numeric features, matrices, and heavy computation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr = np.array([1, 2, 3, 4, 5], dtype=float)\n",
        "arr * 2, arr.mean(), arr.std()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Broadcasting example: standardize features\n",
        "X = np.random.randn(1000, 3) * np.array([10, 2, 1]) + np.array([50, 10, 0])\n",
        "mu = X.mean(axis=0)\n",
        "sigma = X.std(axis=0)\n",
        "\n",
        "Z = (X - mu) / sigma\n",
        "Z.mean(axis=0), Z.std(axis=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 7\n",
        "Create a 2D NumPy array with shape (100, 4) representing 100 patients and 4 features.\n",
        "Compute column means and identify which feature has the largest variance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = np.random.randn(100, 4)\n",
        "col_means = X.mean(axis=0)\n",
        "col_vars = X.var(axis=0)\n",
        "largest_var_feature = int(np.argmax(col_vars))\n",
        "col_means, col_vars, largest_var_feature\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10) pandas Series and DataFrames: labeled data structures\n",
        "pandas is optimized for:\n",
        "- Tabular data\n",
        "- Missing values\n",
        "- Groupby/aggregate\n",
        "- Joining/merging\n",
        "\n",
        "Series = 1D with an index\n",
        "DataFrame = 2D with row index + columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\n",
        "    \"patient_id\": [\"P001\",\"P002\",\"P003\",\"P004\",\"P005\"],\n",
        "    \"bp_sys\": [130, 142, 118, 155, 140],\n",
        "    \"bp_dia\": [82,  90,  76,  95,  88],\n",
        "    \"smoker\": [0, 1, 0, 1, 0],\n",
        "    \"dept\": [\"Cardiology\", \"Cardiology\", \"ER\", \"ER\", \"Oncology\"]\n",
        "})\n",
        "\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Common DS operations\n",
        "df[\"pulse_pressure\"] = df[\"bp_sys\"] - df[\"bp_dia\"]\n",
        "df.sort_values(\"bp_sys\", ascending=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Groupby aggregation\n",
        "df.groupby(\"dept\").agg(\n",
        "    n=(\"patient_id\", \"count\"),\n",
        "    mean_sys=(\"bp_sys\", \"mean\"),\n",
        "    smoker_rate=(\"smoker\", \"mean\"),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 8\n",
        "Filter to systolic BP ≥ 140. Then compute mean systolic BP by department for that subset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "high = df[df[\"bp_sys\"] >= 140]\n",
        "high.groupby(\"dept\")[\"bp_sys\"].mean()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11) Sparse data (optional but useful)\n",
        "Many DS problems have high-dimensional sparse features (e.g., bag-of-words).\n",
        "In those cases, you often store data in a **sparse matrix** (SciPy) instead of a dense NumPy array.\n",
        "\n",
        "We won’t import SciPy here, but the key concept:\n",
        "- Dense: stores all zeros → wastes memory\n",
        "- Sparse: stores only non-zeros → efficient\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12) Graphs: relationships, networks, pathways\n",
        "Graphs model:\n",
        "- Social networks\n",
        "- Knowledge graphs\n",
        "- Patient referral networks\n",
        "- Disease comorbidity networks\n",
        "\n",
        "A simple representation is an **adjacency list** using a dict of lists.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build an undirected graph with adjacency lists\n",
        "graph = {\n",
        "    \"A\": [\"B\", \"C\"],\n",
        "    \"B\": [\"A\", \"D\"],\n",
        "    \"C\": [\"A\", \"D\"],\n",
        "    \"D\": [\"B\", \"C\", \"E\"],\n",
        "    \"E\": [\"D\"]\n",
        "}\n",
        "\n",
        "# BFS: shortest path in an unweighted graph\n",
        "def bfs_shortest_path(graph, start, goal):\n",
        "    q = deque([(start, [start])])\n",
        "    seen = {start}\n",
        "    while q:\n",
        "        node, path = q.popleft()\n",
        "        if node == goal:\n",
        "            return path\n",
        "        for nbr in graph.get(node, []):\n",
        "            if nbr not in seen:\n",
        "                seen.add(nbr)\n",
        "                q.append((nbr, path + [nbr]))\n",
        "    return None\n",
        "\n",
        "bfs_shortest_path(graph, \"A\", \"E\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 9\n",
        "Modify the graph to add a new node `F` connected to `C`.\n",
        "Then find a shortest path from `F` to `E`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "graph2 = {k: v.copy() for k,v in graph.items()}\n",
        "graph2[\"F\"] = [\"C\"]\n",
        "graph2[\"C\"] = graph2[\"C\"] + [\"F\"]\n",
        "\n",
        "bfs_shortest_path(graph2, \"F\", \"E\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13) Trees (brief): hierarchical data\n",
        "Trees appear in:\n",
        "- File systems\n",
        "- Taxonomies (ICD hierarchy)\n",
        "- Decision trees / gradient boosting (model structure)\n",
        "\n",
        "We’ll implement a tiny tree node structure and a depth-first traversal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Node:\n",
        "    def __init__(self, value, children=None):\n",
        "        self.value = value\n",
        "        self.children = children or []\n",
        "\n",
        "# Simple tree\n",
        "root = Node(\"root\", [\n",
        "    Node(\"A\", [Node(\"A1\"), Node(\"A2\")]),\n",
        "    Node(\"B\", [Node(\"B1\")]),\n",
        "    Node(\"C\")\n",
        "])\n",
        "\n",
        "def dfs_values(node):\n",
        "    out = [node.value]\n",
        "    for child in node.children:\n",
        "        out.extend(dfs_values(child))\n",
        "    return out\n",
        "\n",
        "dfs_values(root)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14) Choosing the right structure: mini decision guide\n",
        "- Need **order** and easy appends? → list\n",
        "- Need **unique items** or fast membership? → set\n",
        "- Need **key → value lookup**? → dict\n",
        "- Need **FIFO queue / sliding window**? → deque\n",
        "- Need **top-k** or priority? → heapq\n",
        "- Need **fast numeric computation**? → NumPy array\n",
        "- Need **labeled tabular data**? → pandas DataFrame\n",
        "- Need **relationships/networks**? → graph (adjacency list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15) Capstone mini-lab: frequent items + join + top-k\n",
        "Scenario: You have encounters with diagnosis codes and want:\n",
        "1) Counts per diagnosis\n",
        "2) Join with a reference table (dx → category)\n",
        "3) Top 5 diagnoses overall and by category\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "encounters = pd.DataFrame({\n",
        "    \"encounter_id\": range(1, 21),\n",
        "    \"patient_id\": [f\"P{random.randint(1,5):03d}\" for _ in range(20)],\n",
        "    \"dx\": random.choices([\"I10\",\"E11.9\",\"I25.10\",\"E78.5\",\"J45.909\",\"F32.9\"], k=20)\n",
        "})\n",
        "\n",
        "dx_ref = pd.DataFrame({\n",
        "    \"dx\": [\"I10\",\"E11.9\",\"I25.10\",\"E78.5\",\"J45.909\",\"F32.9\"],\n",
        "    \"category\": [\"HTN\", \"Diabetes\", \"CAD\", \"Lipids\", \"Asthma\", \"Depression\"]\n",
        "})\n",
        "\n",
        "encounters.head(), dx_ref\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1) counts per diagnosis\n",
        "dx_counts = encounters[\"dx\"].value_counts().rename_axis(\"dx\").reset_index(name=\"n\")\n",
        "dx_counts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2) join with reference\n",
        "dx_counts2 = dx_counts.merge(dx_ref, on=\"dx\", how=\"left\")\n",
        "dx_counts2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3) Top 5 overall and by category\n",
        "top5_overall = dx_counts2.sort_values(\"n\", ascending=False).head(5)\n",
        "\n",
        "by_cat = (encounters.merge(dx_ref, on=\"dx\", how=\"left\")\n",
        "          .groupby(\"category\")[\"dx\"]\n",
        "          .count()\n",
        "          .sort_values(ascending=False)\n",
        "         )\n",
        "\n",
        "top5_overall, by_cat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Capstone exercise\n",
        "1) Compute the **top 2 diagnoses per category** (hint: groupby + value_counts, or groupby + apply).\n",
        "2) For each patient, compute their **most common category**.\n",
        "\n",
        "If you get stuck, tell me what you tried and I’ll help you debug it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Starter cell for Capstone exercise (fill in)\n",
        "# 1) Top 2 diagnoses per category\n",
        "\n",
        "tmp = encounters.merge(dx_ref, on=\"dx\", how=\"left\")\n",
        "tmp.head()\n",
        "\n",
        "# Your solution here:\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
